{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa71014d-2187-4b6c-8697-c0d59e2514a4",
   "metadata": {},
   "source": [
    "В этом блокоте приведено использование обученной модели на детекции труб на предоставленном нас наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70817a2f-d7b2-4303-ac85-2e2d64fc3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45550d1f-1a60-49a9-8238-21471c76f1e4",
   "metadata": {},
   "source": [
    "Тут подгружаем YOLO и проверяем, задейтвуется ли видеокарта и CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa23ebd7-a899-461b-9d85-1dbce7869fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\n",
      "\u001b[2K\n",
      "Ultralytics YOLOv8.2.18 рџљЂ Python-3.11.4 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "Setup complete вњ… (8 CPUs, 15.7 GB RAM, 372.1/471.6 GB disk)\n",
      "\n",
      "OS                  Windows-10-10.0.19043-SP0\n",
      "Environment         Windows\n",
      "Python              3.11.4\n",
      "Install             pip\n",
      "RAM                 15.74 GB\n",
      "CPU                 11th Gen Intel Core(TM) i7-11370H 3.30GHz\n",
      "CUDA                11.8\n",
      "\n",
      "matplotlib          вњ… 3.7.2>=3.3.0\n",
      "opencv-python       вњ… 4.9.0.80>=4.6.0\n",
      "pillow              вњ… 9.5.0>=7.1.2\n",
      "pyyaml              вњ… 6.0.1>=5.3.1\n",
      "requests            вњ… 2.31.0>=2.23.0\n",
      "scipy               вњ… 1.11.1>=1.4.1\n",
      "torch               вњ… 2.0.1+cu118>=1.8.0\n",
      "torchvision         вњ… 0.15.2+cu118>=0.9.0\n",
      "tqdm                вњ… 4.66.1>=4.64.0\n",
      "psutil              вњ… 5.9.5\n",
      "py-cpuinfo          вњ… 9.0.0\n",
      "thop                вњ… 0.1.1-2209072238>=0.1.1\n",
      "pandas              вњ… 2.0.3>=1.1.4\n",
      "seaborn             вњ… 0.12.2>=0.11.0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1a06b-1a63-4713-9bdd-3b63a281ddc6",
   "metadata": {},
   "source": [
    "в model_hope указывается путь по весов модели\n",
    "В path путь в файлам, которые мы хотим \"кормить\" можели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f82b5b51-6330-4781-a077-3c314dc8d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hope = YOLO(r'C:/Users/PyatnitskayaOT/PycharmProjects/yolov8/runs/detect/train3/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc2970-2795-475a-bbe4-39d6ad8a189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce11814-3434-4801-84f4-1ff5bf581c28",
   "metadata": {},
   "source": [
    "\"Кормим\" модель картинками из папки нужным нам образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df4d4085-1dc0-459c-bb89-17f73cb6d65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.18.jpeg: 480x640 105 0s, 21.0ms\n",
      "image 2/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.19 (1).jpeg: 480x640 45 0s, 18.9ms\n",
      "image 3/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.19.jpeg: 480x640 124 0s, 18.0ms\n",
      "image 4/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.20 (1).jpeg: 480x640 45 0s, 18.0ms\n",
      "image 5/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.20.jpeg: 480x640 131 0s, 18.0ms\n",
      "image 6/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.21 (1).jpeg: 480x640 108 0s, 18.0ms\n",
      "image 7/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.21.jpeg: 640x480 81 0s, 94.9ms\n",
      "image 8/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.22.jpeg: 480x640 254 0s, 20.0ms\n",
      "image 9/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23 (1).jpeg: 480x640 294 0s, 18.0ms\n",
      "image 10/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23 (2).jpeg: 480x640 153 0s, 18.0ms\n",
      "image 11/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23.jpeg: 480x640 159 0s, 18.0ms\n",
      "image 12/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (1).jpeg: 480x640 227 0s, 19.0ms\n",
      "image 13/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (2).jpeg: 480x640 261 0s, 18.0ms\n",
      "image 14/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (3).jpeg: 480x640 36 0s, 19.0ms\n",
      "image 15/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26.jpeg: 640x480 300 0s, 19.0ms\n",
      "image 16/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.27 (1).jpeg: 480x640 284 0s, 18.0ms\n",
      "image 17/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.27.jpeg: 480x640 246 0s, 18.0ms\n",
      "image 18/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.28.jpeg: 640x480 91 0s, 18.0ms\n",
      "image 19/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.30 (1).jpeg: 480x640 44 0s, 21.0ms\n",
      "image 20/20 C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.30.jpeg: 480x640 117 0s, 18.0ms\n",
      "Speed: 4.8ms preprocess, 22.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = model_hope.predict(path, save=True, conf=0.8, show_conf=False, show_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "95905b3a-dc3b-41ee-9c58-a38102a7c019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#вывод количества обнаруженных дыр на одной конретной фотке\n",
    "result[10].boxes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef6e012-0b68-4787-97e0-43b2f59e5644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.18.jpeg\n",
      "105\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.19 (1).jpeg\n",
      "45\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.19.jpeg\n",
      "124\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.20 (1).jpeg\n",
      "45\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.20.jpeg\n",
      "131\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.21 (1).jpeg\n",
      "108\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.21.jpeg\n",
      "81\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.22.jpeg\n",
      "254\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23 (1).jpeg\n",
      "294\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23 (2).jpeg\n",
      "153\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23.jpeg\n",
      "159\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (1).jpeg\n",
      "227\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (2).jpeg\n",
      "261\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (3).jpeg\n",
      "36\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26.jpeg\n",
      "300\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.27 (1).jpeg\n",
      "284\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.27.jpeg\n",
      "246\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.28.jpeg\n",
      "91\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.30 (1).jpeg\n",
      "44\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.30.jpeg\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "#цикл по result, путь к картинке + количество обнаруженных на ней дырок\n",
    "for n in range(0,20):\n",
    "    print(result[n].path)\n",
    "    print(result[n].boxes.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222888a-786b-4793-aee5-98593ee9eac7",
   "metadata": {},
   "source": [
    "Тут мы \"дорисовываем\" на картинках с Bounding boxes их количество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf9f4ba9-997c-4678-b47b-94b9e4a9fd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhatsApp Image 2024-05-19 at 16.27.18.jpeg\n",
      "0\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.18.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.19 (1).jpeg\n",
      "1\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.19 (1).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.19.jpeg\n",
      "2\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.19.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.20 (1).jpeg\n",
      "3\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.20 (1).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.20.jpeg\n",
      "4\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.20.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.21 (1).jpeg\n",
      "5\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.21 (1).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.21.jpeg\n",
      "6\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.21.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.22.jpeg\n",
      "7\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.22.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.23 (1).jpeg\n",
      "8\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23 (1).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.23 (2).jpeg\n",
      "9\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23 (2).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.23.jpeg\n",
      "10\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.23.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.26 (1).jpeg\n",
      "11\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (1).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.26 (2).jpeg\n",
      "12\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (2).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.26 (3).jpeg\n",
      "13\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26 (3).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.26.jpeg\n",
      "14\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.26.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.27 (1).jpeg\n",
      "15\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.27 (1).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.27.jpeg\n",
      "16\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.27.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.28.jpeg\n",
      "17\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.28.jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.30 (1).jpeg\n",
      "18\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.30 (1).jpeg\n",
      "WhatsApp Image 2024-05-19 at 16.27.30.jpeg\n",
      "19\n",
      "C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\cap\\WhatsApp Image 2024-05-19 at 16.27.30.jpeg\n"
     ]
    }
   ],
   "source": [
    "# path_predict - папка с картинками\n",
    "# path_writr - куда сохраняем снимки с дорисованнным количеством \n",
    "path_predict = r'C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\runs\\detect\\predict'\n",
    "path_write = r'C:\\Users\\PyatnitskayaOT\\PycharmProjects\\yolov8\\hakaton_05_24\\runs\\detect\\new'\n",
    "# Перебираем все файлы в папке predict и рисуем на них количество дырок, сохраняем в new\n",
    "n = 0\n",
    "for file in os.listdir(path_predict):\n",
    "    # Получаем полный путь к файлу\n",
    "    full_path = os.path.join(path_predict, file)\n",
    "    #выводим имя файла, значение счетсика, соответсвующее количество из result\n",
    "    print(file)\n",
    "    print(n)\n",
    "    print(result[n].path)\n",
    "    #загружаем картинку\n",
    "    frame = cv2.imread(full_path)\n",
    "    #рисуем на картинке в левом верхнем углу белую линию\n",
    "    frame1 = cv2.line(frame,(0,52),(200,52),(255,255,255),110) \n",
    "    #на нарисованной белой линии пишем количество объектов на картинке из result\n",
    "    frame1 = cv2.putText(frame1, str(result[n].boxes.shape[0]), (0,100), cv2.FONT_HERSHEY_SIMPLEX, 4, (0,0, 255), 5)\n",
    "    #сохраняем новую картинку\n",
    "    cv2.imwrite(os.path.join(path_write, str(n)+ '.jpg'), frame1)\n",
    "    #увеличиваем значение счетчика\n",
    "    n+= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2bd3e-c866-4e4e-8b61-4d181ec19d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16c44df6-fb61-47eb-9012-4716c8ce475e",
   "metadata": {},
   "source": [
    "Далее у нас код с подсчетом труб в конкретном участве кадра на видео\n",
    "Имя нужного видео файла указываетя в  cap\n",
    "В region_points задем область интеереса\n",
    "В video_writer указваем име выходного файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cccad75-a581-4a8f-a1c8-1b390bf343e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720\n",
      "Polygon Counter Initiated.\n",
      "\n",
      "0: 384x640 3 0s, 21.0ms\n",
      "Speed: 5.0ms preprocess, 21.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 5.0ms preprocess, 16.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 6.0ms preprocess, 17.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 6.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 20.0ms\n",
      "Speed: 5.0ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 6.0ms preprocess, 16.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 8.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 5.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 6.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 15.0ms\n",
      "Speed: 6.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 8.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 16.0ms\n",
      "Speed: 7.0ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 18.0ms\n",
      "Speed: 7.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 23.0ms\n",
      "Speed: 4.0ms preprocess, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 18.0ms\n",
      "Speed: 9.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 7.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 6.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 19.0ms\n",
      "Speed: 8.0ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 19.0ms\n",
      "Speed: 8.0ms preprocess, 19.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 7.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 17.0ms\n",
      "Speed: 7.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 22.0ms\n",
      "Speed: 4.0ms preprocess, 22.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 19.0ms\n",
      "Speed: 8.0ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 40.0ms\n",
      "Speed: 6.0ms preprocess, 40.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 0s, 22.0ms\n",
      "Speed: 4.0ms preprocess, 22.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 17.0ms\n",
      "Speed: 6.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 9.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 34.0ms\n",
      "Speed: 4.0ms preprocess, 34.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 17.0ms\n",
      "Speed: 9.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 22.0ms\n",
      "Speed: 4.0ms preprocess, 22.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 8.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 35.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 9.0ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 20.0ms\n",
      "Speed: 5.0ms preprocess, 20.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 6.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 35.0ms\n",
      "Speed: 8.0ms preprocess, 35.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 19.0ms\n",
      "Speed: 5.0ms preprocess, 19.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 7.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 21.0ms\n",
      "Speed: 4.0ms preprocess, 21.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 19.0ms\n",
      "Speed: 6.0ms preprocess, 19.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 19.0ms\n",
      "Speed: 5.0ms preprocess, 19.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 7.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 31.0ms\n",
      "Speed: 5.0ms preprocess, 31.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 8.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 23.0ms\n",
      "Speed: 4.0ms preprocess, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 22.0ms\n",
      "Speed: 4.0ms preprocess, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 7.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 6.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 19.0ms\n",
      "Speed: 5.0ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 7.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 22.0ms\n",
      "Speed: 5.0ms preprocess, 22.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 7.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 19.0ms\n",
      "Speed: 8.0ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 9.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 8.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 0s, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo frame is empty or video processing has been successfully completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m tracks \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m im0 \u001b[38;5;241m=\u001b[39m counter\u001b[38;5;241m.\u001b[39mstart_counting(im0, tracks)\n\u001b[0;32m     34\u001b[0m video_writer\u001b[38;5;241m.\u001b[39mwrite(im0)\n",
      "File \u001b[1;32m~\\PycharmProjects\\yolov8\\venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:493\u001b[0m, in \u001b[0;36mModel.track\u001b[1;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[0;32m    492\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\yolov8\\venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:453\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\yolov8\\venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\PycharmProjects\\yolov8\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\yolov8\\venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:255\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m--> 255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_postprocess_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\yolov8\\venv\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\predict.py:25\u001b[0m, in \u001b[0;36mDetectionPredictor.postprocess\u001b[1;34m(self, preds, img, orig_imgs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds, img, orig_imgs):\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Post-processes predictions and returns a list of Results objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnon_max_suppression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43magnostic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magnostic_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_det\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig_imgs, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# input images are a torch.Tensor, not a list\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         orig_imgs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_torch2numpy_batch(orig_imgs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\yolov8\\venv\\Lib\\site-packages\\ultralytics\\utils\\ops.py:220\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[1;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001b[0m\n\u001b[0;32m    218\u001b[0m nm \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m nc \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m    219\u001b[0m mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m nc  \u001b[38;5;66;03m# mask start index\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m xc \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mmi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mamax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m conf_thres  \u001b[38;5;66;03m# candidates\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Settings\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# min_wh = 2  # (pixels) minimum box width and height\u001b[39;00m\n\u001b[0;32m    224\u001b[0m time_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m+\u001b[39m max_time_img \u001b[38;5;241m*\u001b[39m bs  \u001b[38;5;66;03m# seconds to quit after\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO, solutions\n",
    "\n",
    "model = model_hope\n",
    "cap = cv2.VideoCapture(\"video0.mkv\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "print(w,h)\n",
    "# Define region points as a polygon\n",
    "#(x1,y1)(x1,y2)(x2,y2)(x2,y1)\n",
    "region_points = [(500, 470), (500, 678), (950, 678), (950, 470)]\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"output0.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init Object Counter\n",
    "counter = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=region_points,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    ")\n",
    "#cap.isOpened()\n",
    "while True:\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    tracks = model.track(im0, persist=True, show=False)\n",
    "\n",
    "    im0 = counter.start_counting(im0, tracks)\n",
    "    video_writer.write(im0)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6e7ab1-ba6c-4e66-8c0a-e97c102d5885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 1080\n",
      "Polygon Counter Initiated.\n",
      "Video frame is empty or video processing has been successfully completed.\n"
     ]
    }
   ],
   "source": [
    "#линия\n",
    "import cv2\n",
    "from ultralytics import YOLO, solutions\n",
    "\n",
    "model = YOLO(r'C:/Users/PyatnitskayaOT/PycharmProjects/yolov8/runs/detect/train3/weights/best.pt')\n",
    "cap = cv2.VideoCapture(\"video2.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "print(w,h)\n",
    "#(x1,y1)(x1,y2)(x2,y2)(x2,y1)s\n",
    "#line_points = [(3, 255),(3, 750), (800, 900),(1100,900),(1100,255)]\n",
    "# Define line points\n",
    "line_points = [(675, 525),(675, 1000),(1400, 1000),(1400,525)]\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"output2.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init Object Counter\n",
    "counter = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=3,\n",
    "    region_thickness = 10\n",
    "    \n",
    ")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    tracks = model.track(im0, persist=True, show=False, conf=0.2, verbose=False)\n",
    "\n",
    "    im0 = counter.start_counting(im0, tracks)\n",
    "    video_writer.write(im0)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606db191-d120-4d92-bba1-9a195a02a593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549c0f9-e8d7-49cf-9649-9a621e4e4c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
